\section {\textit{Netwok Time Protocol} - NTPv4}

\subsection {Introdução}

O protocolo NTP implementa diversas soluções que permitem a sincronização dos
relógios dos computadores pertencentes a uma determinada rede. O protocolo
utiliza diversas métricas, descritas nas próximas seções, a fim de determinar
quais são as fontes mais seguras e consistentes para obter a melhor
sincronização e uma maior precisão. Somadas a essas estatísticas, o NTP faz uso
de algoritmos de seleção, \textit{cluster} e combinação que garantem, por sua
vez, a determinação dos servidores mais confiáveis a partir de um número finito
de amostras provindas de tais fontes. 

\vspace{12pt}

A troca de mensagens é feita através de pacotes UDP, sendo que o protocolo
suporta tanto o IPv4 quanto o IPv6. Apesar do fato de que o protocolo UDP não
oferece garantias de entrega e correção de eventuais erros ou duplicatas, o
NTPv4 implementa mecanismos, tais como o \textit{On-Wire protocol}, capazes de
verificar a consistência dos dados contidos nos pacotes recebidos e, assim,
agir corretamente em casos de perdas ou pacotes repetidos.

\vspace{12pt}

Neste relatório, serão discutidas as características da versão 4 do NTP,
especificadas no RFC5905. Esta versão aprimora alguns aspectos da versão 3
(NTPv3) e adiciona algumas outras funcionalidades, como, por exemplo, a
descoberta dinâmica de servidores (\textit{automatic server discovery}),
sincronização rápida na inicialização da rede ou depois de falhas
(\textit{burst mode}) e uso da criptografia \textit{Public-key}.

\subsection {Características do Protocolo}

O primeiro aspecto importante do protocolo NTPv4 é a organização dos
nós de uma rede. O NTP provê 3 tipos diferentes de variantes 
e 6 modos de associação, que identificam a função de cada nó que
compõe um comunicação. As variantes NTP são, portanto:

\begin {enumerate}[i.]
  
  \item \textit{server/client}: um cliente envia pacotes a um servidor
  requisitando sincronização, que responde utilizando o endereço contido nos
  respectivos pacotes. Nesta variante, servidores fornecem sincronização aos
  clientes, mas não aceitam sincronizações vindas dos clientes. As associações
  entre os nós nesta variante são persistentes, ou seja, são criadas na
  inicialização do serviço e nunca são destruídas.
  
  \item \textit{symmetric}: neste tipo de variante, um nó se comporta tanto como
  servidor como cliente, isto é, ele recebe e envia informações de sincronização
  ao outro nó. Associações deste tipo podem ser persistentes, conforme explicado
  no item anterior, ou temporárias, isto é, podem ser criadas a partir do
  recebimento de um pacote e eliminadas após um certo intervalo ou ocorrência
  de erro. No primeiro caso, adota-se uma associação \textit{ativa}, enquanto
  que na segunda, adota-se uma \textit{passiva}.
      
  \item \textit{broadcast}: nesta variante, um servidor \textit{broadcast}
  persistente envia pacotes que podem ser recebidos por diversos clientes.
  Quando um cliente recebe um pacote deste tipo, uma associação temporária do
  tipo \textit{broadcast client} é criada e o cliente recebe sincronização até o
  fim de um intervalo ou ocorrência de um erro.
  
\end{enumerate}

O protocolo oferece ainda uma funcionalidade que permite aos clientes
descobrirem servidores disponíveis na rede para sincronização. Tal mecanismo é
chamado de \textit{Dynamic Server Discovery}, que provê dois tipos especiais de
associação: \textit{manycast server} e \textit{manycast client}. Um cliente
\textit{manycast} persistente envia pacotes para endereços de \textit{broadcast}
ou \textit{multicast} e, caso um \textit{manycast server} receba tais pacotes,
ele envia uma resposta a determinado cliente, que, por sua vez, mobiliza uma
associação temporária com o respectivo servidor. A fim de descobrir os
servidores mais próximos, os clientes enviam pacotes com TTL crescentes, até que
o número mínimo de servidores descobertos seja atingido.

\vspace{12pt}

O segundo aspecto importante é a implementação dos processos que são executados
em um sistema a fim de garantir as funcionalidades apresentadas acima. Cada nó
da rede utiliza dois processos dedicados para cada servidor que provê
sincronização, além de 3 outros dedicados para escolha dos melhores candidatos
e ajuste do relógio. A figura \ref{fig:modelo} esquematiza a relação entre tais
processos. As flechas representam trocas de dados entre processos ou algoritmos.
 
\FloatBarrier

\begin{figure}[h]
    
    \centering
    \includegraphics[scale=0.5]{image/ntp_implementation}
    \caption {Implementação dos processos executados por um nó da rede.}
    \label{fig:modelo}
\end{figure} 

\FloatBarrier

Cada componente é, portanto, responsável por uma funcionalidade específica
oferecida pelo NTP. Temos, assim:

\begin {enumerate}[i.]
  \item \textit{Remote servers}: servidores que fornecem sincronização aos nós
  da rede. Tais servidores podem pertencer à mesma rede às quais os clientes
  estão inseridos ou podem ser disponibilizados via Internet por organismos
  responsáveis por gerenciar e garantir que os relógios apresentem tempos
  consistentes. 
  
  A fim de diferenciar os diversos servidores utilizados em relação ao seu grau
  de importância e confiabilidade, o protocolo NTP atribui um nível a cada
  \textit{server}, chamado de \textit{stratum}. Tal atributo vale 1 para
  servidores primários, 2 para servidores secundários e assim sucessivamente. À
  medida que o valor de \textit{stratum} aumenta, a precisão diminui,
  dependendo do estado da rede. O valor máximo deste atributo é 15 e, portanto,
  são permitidos até 15 níveis hierárquicos. O valor 0 é reservado pelo
  protocolo para mensagens de controle e transmissão de estado entre nós. Tais
  mensagens são chamadas de pacotes \textit{Kiss-o'-Death}.
  
%   Caso \textit{stratum} de determinado servidor apresente o valor
%   16, isso significa que o cliente que está tentando obter sincronização está
%   dessincronizado com tal servidor.
  
  \item \textit{Peer/poll processes}: quando um pacote transmitido por um
  servidor chega em um nó, o \textit{peer process} é chamado. Tal processo então
  verifica se o pacote é consistente (\textit{On-Wire protocol}, proteção
  contra perdas e duplicatas) e calcula algumas estatísticas usadas pelos demais
  processos. Tais estatíticas consistem em:
  		
  		\begin{itemize}
  		  \renewcommand\labelitemi{--}
  		  \item \textit{offset} (\(\theta\)): deslocamento de tempo do
  		  relógio do servidor em relação ao relógio do sistema;
  		  \item \textit{delay} (\(\delta\)): tempo que o pacote necessita para
  		  percorrer toda a rede entre cliente e servidor;
  		  \item \textit{dispersion} (\( \epsilon \)): erro máximo inerente à medida
  		  do relógio do sistema;
  		  \item \textit {jitter} (\( \psi \)): raiz do valor quadrático médio dos
  		  \textit{offsets} mais recentes.
  		\end{itemize}
  		
	O \textit{poll process} é responsável, por sua vez, por enviar pacotes aos
	servidores a cada intervalo de \(2^\tau\) segundos. \(\tau\) varia de 4 a 17,
	resultando, assim, em intervalos de 16 segundos a 36 horas. O valor de \(\tau\)
	pode variar durante a execução, sendo modificado pelo algoritmo regulador do
	relógio, que será discutido posteriormente. 
	
	\item \textit{System process}: inclui algoritmos de seleção, clusterização e
	combinação que utilizam as diversas estatísticas obtidas de cada servidor para
	determinar os candidatos mais precisos e confiáveis à sincronização do relógio
	do sistema. As funções de cada algoritmo são, respectivamente:
		
		\begin{itemize}
  		  \renewcommand\labelitemi{--}
  		  \item determinar bons candidatos, isto é, determinar quais servidores
  		  possuem informações de sincronismo efetivamente importantes;
  		  \item determinar os melhores candidatos dentro do conjunto de servidores
  		  julgados importantes no passo anterior;
  		  \item computar estatísticas baseadas nos dados recolhidos dos servidores
  		  presentes no subconjunto escolhido pelo algoritmo de clusterição.
  		\end{itemize}
  	
  	\item \textit{Clock discipline process}: responsável por controlar o tempo e
  	frequência do relógio do sistema;
  	
  	\item \textit{Clock-adjust process}: roda a cada segundo para comunicar aos
  	demais processos os resultados das correções realizadas no relógio do
  	sistema.
  	
\end{enumerate}

\subsection {Exemplo}

A rede representada pela figura \ref{fig:redeNTP} foi proposta a fim de testar o
funcionamento do protocolo NTP. As setas determinam as relações entre os nós e
as direções representam quais nós fornecem e/ou recebem sincronização. Todos os
computadores pertencem à mesma rede, isto é, assume-se que há um \textit{router}
ligando esses nós e responsável pela comunicação com a Internet.

\FloatBarrier

\begin{figure}[h]
    
    \centering
    \includegraphics[scale=0.7]{image/rede_ntp_teste}
    \caption {Topologia da rede de teste.}
    \label{fig:redeNTP} 
\end{figure} 

\FloatBarrier

Têm-se, portanto, conforme a subseção anterior:

\begin{itemize}
  \renewcommand\labelitemi{--}
  \item associações cliente/servidor entre \textit{remote servers} e
  \textit{servers}, e entre \textit{servers} e \textit{clients};
  \item associações simétricas ativas entre \textit{servers}.
\end{itemize}

A fim de eliminar a necessidade de implementar essa rede fisicamente,
utilizou-se o \textit{software virtualbox}. Cada máquina presente na figura, com
exceção dos \textit{remote servers}, foi substituída por uma máquina virtual,
cujo sistema operacional é o \textit{Linux Debian 8.2.0 i386}. A escolha deste
sistema foi baseada nas características previstas para as máquinas que comporão
a infraestrutura do Sirius. Além disso, como pretende-se isolar completamente a
rede, isto é, eliminar qualquer comunicação com a Internet, os \textit{remote
servers} serão substituídos pelos respectivos servidores. Dessa maneira, tais
servidores utilizarão seus próprios relógios como fonte primária de sincronismo.

\vspace{12pt}

Foi adotado que a rede teria endereço \texttt{10.0.0.0/24}, os servidores
possuiriam endereços do tipo \texttt{10.0.0.10x}, sendo \textit{x} o dígito que
caracteriza o servidor (1, 2 ou 3), e \texttt{10.0.0.0y1} para os clientes,
sendo \textit{y} o equivalente de \textit{x}. 


\vspace{12pt}

Após a configuração de rede das respectivas máquinas virtuais, a instalação do
NTP pode prosseguir. Inicialmente, é necessário fazer a instalação do pacote
\texttt{ntp} através do comando

\begin{lstlisting}[language=bash, style=nonumbers]
$ sudo apt-get install ntp
\end{lstlisting}

Estão incluídos neste pacote, os programas \texttt{ntpd}, \texttt{ntpq}
e \texttt{ntpqc}. \texttt{ntpd}, ou \textit{NTP Daemon}, roda continuamente no
sistema e é responsável pela troca de mensagens com os diversos servidores
ou clientes, de acordo com as configurações, enquanto que \texttt{ntpq}
e \texttt{ntpqc} (o \textit{q} refere-se a \textit{query}) são utilizados para
verificar o estado das variáveis e alterar configurações do \textit{daemon}. 

\vspace{12pt}

Quando é iniciado, o \textit{daemon} retira as suas configurações do arquivo
\texttt{/etc/ntp.conf}. Cada nó da rede deve, portanto,
configurar esse arquivo de acordo com as funções que desempenha.

\vspace{12pt}

A configuração dos clientes é simples: basta adicionarmos a linha

\begin{lstlisting}[language=bash, style=nonumbers]
server 10.0.0.10y iburst
\end{lstlisting}

ao arquivo de configurações. A opção \texttt{iburst} é uma otimização fornecida
pelo protocolo que agiliza a sincronização inicial. Essa opção faz com que o
intervalo de envio de pacotes seja reduzido e a quantidade de pacotes
enviados seja aumentada caso o servidor não esteja acessível. 

\vspace{12pt}

Para o \textit{server 2}, é necessário adicionarmos as duas linhas seguintes.

\begin{lstlisting}[language=bash, style=nonumbers]
peer 10.0.0.101
peer 10.0.0.103
\end{lstlisting}

Essas duas linhas criam associações simétricas ativas entre o \textit{server 2}
e os outros servidores. Dessa maneira, eles poderão trocar informações de
sincronização entre si.

\vspace{12pt}

Para os servidores 1 e 3, além das duas linhas contendo a opção \texttt{peer}, é
necessário também adicionar as duas linhas abaixo:

\begin{lstlisting}[language=bash, style=nonumbers]
server 127.127.0.0
fudge 127.127.0.0 stratum 1
\end{lstlisting}

A primeira opção configura o relógio local do sistema como uma fonte de
sincronização, enquanto que a segunda aumenta a sua hierarquia. Se o
atributo \texttt{stratum} vale 1, logo a prioridade do respectivo servidor
torna-se máxima.

\vspace{12pt}

Para iniciar o \textit{daemon}, basta executar o comando abaixo em cada máquina.

\begin{lstlisting}[language=bash, style=nonumbers]
$ sudo /etc/init.d/ntp restart
\end{lstlisting}

Os sistemas levam alguns minutos para se sincronizarem. Para verificar o estado
das conexões e da sincronização, utiliza-se o programa \texttt{ntpq} através do
comando 

\begin{lstlisting}[language=bash, style=nonumbers]
$ ntpq -p
\end{lstlisting}

A opção \texttt{-p} lista todos os nós utilizados para sincronização do relógio
local. Para o \textit{Server 1}, espera-se uma saída parecida com a figura
\ref{fig:sv1} (não há garantias que seja idêntica, visto que os algoritmos que
determinam as fontes que serão utilizadas para sincronização são baseados em
fatores que podem variar dependendo do estado da rede). 

\FloatBarrier

\begin{figure}[h]
    
    \centering
    \includegraphics[scale=0.7]{image/server1_screen}
    \caption {Resultado do comando \texttt{ntpq -p} no \textit{Server 1}.}
    \label{fig:sv1} 
\end{figure} 

\FloatBarrier

O caracter \texttt{*} indica quais dos servidores está sendo usado como fonte de
sincronismo e o \texttt{+} indica os outros possíveis candidatos válidos (os
chamados \textit {truechimers}). É possível também encontrar o caracter
\texttt{-}, representando servidores que provêm fontes de sincronismo inválidas
(chamadas também de \textit{falsetickers}). \texttt{refid} representa o
\textit{id} da refêrencia de sincronismo do respectivo servidor. Por exemplo, o
nó \texttt{10.0.0.103} usa como referência o relógio \texttt{LOCAL(0)}, que o
próprio relógio da máquina. \texttt{st} é o valor do \textit{stratum}. Conforme
esperado, servidores secundários, como \texttt{10.0.0.103}, que possuem somente
uma fonte de sincronismo, têm esse atributo setado para 2. \texttt{when}
corresponde ao tempo, em segundos, da última troca de pacotes e \texttt{poll} é
o tempo em segundos até o próximo envio. \texttt{reach}, em representação octal,
indica se as 8 últimas tentativas de comunicação foram bem-sucedidas ou não. 
Esse atributo funciona como um registrador que é deslocado para a esquerda a
cada nova comunicação. Se ela for bem-sucedida, o \textit {bit} mesmo
significativo é setado para 1, senão, para 0. As demais colunas são as
estatísticas comentadas na subseção anterior.

\vspace{12pt}

A figura \ref{fig:cl1} é a saída do comando \texttt{ntpq -p} no cliente
conectado no \textit{server 1}. Conforme esperado, ele obtem corretamente a
sincronização deste servidor.

\FloatBarrier

\begin{figure}[h]
    
    \centering
    \includegraphics[scale=0.7]{image/client1_screen}
    \caption {Resultado do comando \texttt{ntpq -p} no \textit{Client 1}.}
    \label{fig:cl1}  
\end{figure} 

\FloatBarrier
\subsection {Aplicação ao sistema de controle do \textit{Sirius}}

Considerando que o sistema de controle do \textit{Sirius} será composto por uma
vasta quantidade de \textit{Beagles} conectadas, é de extrema importância que a
data e hora de todas elas estejam corretamente sincronizadas entre si, a fim de
garantir a coerência entre os diversos \textit{logs} que serão gerados na
execução dos programas. Conforme discutido na subseção anterior, um servidor NTP
é capaz de fornecer sincronismo a um número variável de clientes, desde que eles
estejam configurados a obter sincronização deste servidor.

\vspace{12pt}  

Diversos institutos fornecem, através da Internet, relógios de referência, isto
é, servidores chamados de \textit{stratum 0}, obtidos a partir de equipamentos
como \textit{GPS}, relógios atômicos ou outros \textit{radio clocks}. Para a rede
de controle do \textit{Sirius}, que pretende ser totalmente isolada de redes
externas, tal solução não pode ser obviamente utilizada. Sendo assim, propõe-se
a implementação de um servidor NTP \textit{stratum 0} a partir de um GPS
\textit{receiver}, ligado a uma \textit{BeagleBone Black} dedicada, que
hospedará o servidor.

\vspace{12pt}

\textit{GPS receivers} são capazes de fornecer, além do posicionamento e
velocidade, data e hora no padrão \textit{UTC} e um pulso, chamado de
\textit{1PPS}, com frequência de 1Hz e precisão na ordem de \(50ns\). Pode-se
imaginar que somente o horário fornecido é suficiente para a implementação de um
bom servidor NTP. Entretanto, os \textit{delays} com que tal informação é
recebida (\textit{fix reports}) e transmitida pelo \textit{receiver} não são
constantes e variam conforme temperatura. Dessa forma, a fim de obter um tempo
preciso, um pulso de 1PPS, com latência baixa e constante (ou quase constante)
em relação ao tempo do \textit{fix report}, é fornecido. A combinação destes
dois últimos, aliados a um sistema operacional com \textit{kernel} habilitado ao
tratamento de tais pulsos, permite a implementação de um servidor com acurácia
da ordem de \(1\mu s\) em relação ao horário \textit{real}.

\vspace{12pt}

As próximas subseções visam descrever o \textit{hardware} utilizado e a
configuração do servidor NTP.

\subsubsection{Descrição do \textit{hardware}}

Dois módulos GPS de fabricantes distintos foram comprados:

\begin{enumerate}[i.]
  \item \textit{Adafruit Ultimate GPS Breakout - 66 channel w/10 Hz}.
  \item \textit{U-blox 6H}
\end{enumerate}

Ambos fornecem um pino de saída 1PPS e comunicação serial assíncrona
\textit{RX/TX} (\textit{UART}). Foi utilizado também o multivibrador mono
estável \textit{74HC123}, a fim de obtermos um pulso 1PPS mais largo na entrada
do pino da \textit{BeagleBone Black}. Tal pulso é fornecido com uma largura de
apenas \(10\mu s\), que pode não ser capturado pela placa, dependendo da
utilização da sua CPU. Sendo assim, utilizando-se um resistor de \(22k\Omega\) e um
capacitor de \(10nF\), obtém-se uma largura de aproximadamente \(100 \mu s\).

\subsubsection{Configuração do servidor NTP}

O primeiro passo para a implementação é a preparação do \textit{kernel} do
\textit{Linux} para o tratamento de pulsos 1PPS. Isso pode ser realizado pela
compilação do \textit{kernel} (ver subseção \ref{kernel-linux}) habilitando esta
opção ou a partir da instalação do pacote \texttt{pps-tools} a partir do comando
\path{apt-get} \path{install}.

\vspace{12pt}

A segunda etapa consiste na configuração das portas de entrada e
saída que serão usadas pela \textit{BeagleBone Black} para se comunicar com o
GPS. Conforme referência [1], adotaremos que os pinos \texttt{P9-11} e
\texttt{P9-13} serão utilizados, respectivamente, como \textit{TX} e
\textit{RX}, e \texttt{P8-7}, como entrada do pulso 1PPS. O arquivo de
\textit{device tree overlay} especificando tais comportamentos pode ser obtido
a partir de \url{http://tinyurl.com/oeo2ccu}. Após compilado e carregado, duas
novas  interfaces estarão disponíveis, sendo elas \path{/dev/ttyO4} e
\path{/dev/pps0}. Para habilitar o carregamento deste \textit{overlay} após o
\textit{boot}, é necessário editar os arquivos \path{/boot/uEnv.txt} e
\path{/etc/default/capemgr} com, respectivamente,
\path{cape_enable=capemgr.enable_portno=overlay_GPS} e \path{CAPE=overlay_GPS}.

\vspace{12pt}
 
A comunicação com o \textit{GPS receiver} é realizado por meio do
\textit{daemon GPSD}. Após instalá-lo, crie o arquivo
\path{/lib/systemd/system/gpsd.service} e adicione as seguintes linhas:

\begin{lstlisting}[keywordstyle=\ttfamily, style=nonumbers]
[Unit]
Description=GPS (Global Positioning System) Daemon
Requires=gpsd.socket

[Service]
ExecStart=/usr/sbin/gpsd -n -N /dev/ttyO4

[Install]
Also=gpsd.socket
\end{lstlisting}

O \textit{daemon} pode ser iniciado com
 
\begin{lstlisting}[keywordstyle=\ttfamily, style=nonumbers]
systemctl start gpsd.service
\end{lstlisting}

O programa \texttt{gpsmon}, provido no pacote
\path{gpsd-clients}, permite verificar se a conexão entre a \textit{BeagleBone}
o módulo GPS está correta.

\vspace{12pt}

A configuração do NTP é ligeiramente mais complicada, visto que é necessário
recompilá-lo de maneira a habilitar o uso do \textit{driver} responsável por
manipular o pulso 1PPS. Para tal, faça o \textit{download} do código fonte em
\url{http://www.ntp.org/downloads.html} e extraia seu conteúdo para o diretório
de preferência. Em seguida, entre neste diretório e execute o comando abaixo. As
\textit{flags} \texttt{--enable-ATOM} e \texttt{--prefix} especificam,
respectivamente, a ativação do \textit{driver} de gerenciamento do 1PPS e o
diretório onde o NTP será instalado.

\begin{lstlisting}[keywordstyle=\ttfamily, style=nonumbers]
./configure --enable-ATOM --prefix=/INSTALL_DIR --enable-linuxcaps
\end{lstlisting}

O comando \texttt{make install} instalará os binários no diretório especificado.
O pacote \texttt{libcap-dev} é necessário e, portanto, deve ser instalado via
\texttt{apt-get install}. Enfim, a última etapa consiste em atualizar os
arquivos \texttt{ntpdate.service} e \texttt{ntpd.service} para que os serviços sejam
inicializados assim que a \textit{BeagleBone} for ligada. Para tal, implementei
um \textit{script bash}, encontrado no repositório do grupo, que
realiza automaticamente esta tarefa.

\subsection{Construção de um \textit{cape} para a \textit{BeagleBone Black}}

\textit{Seção a ser completada no decorrer das atividades.}

\subsection{Resultados}

\textit{Seção a ser completada no decorrer das atividades.}